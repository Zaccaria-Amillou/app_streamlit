{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Bert Model"]},{"cell_type":"markdown","metadata":{},"source":["### 1. Import Packages, function et charghement donnees"]},{"cell_type":"markdown","metadata":{},"source":["#### 1.1 Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":25277,"status":"ok","timestamp":1712663956377,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"NJfK72XdpfcS"},"outputs":[],"source":["# libraries standard\n","import numpy as np\n","import pandas as pd\n","import random\n","import re\n","\n","# dataviz\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# ml et data handling\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, TensorDataset, random_split\n","\n","# BERT\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n","\n","# Experiment tracking\n","import mlflow\n","import mlflow.pytorch"]},{"cell_type":"markdown","metadata":{},"source":["#### 1.2 Functions"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def accuracy(preds, labels):\n","    \"\"\"\n","    Calcule la précision des prédictions.\n","\n","    Args:\n","        preds: Les prédictions du modèle.\n","        labels: Les étiquettes réelles.\n","\n","    Returns:\n","        float: La précision des prédictions.\n","\n","    \"\"\"\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    label_flat = labels.flatten()\n","    return np.sum(pred_flat == label_flat) / len(label_flat)\n","\n","\n","def evaluate(dataloader_test):\n","    \"\"\"\n","    Évalue les performances du modèle sur un ensemble de données de test.\n","\n","    Args:\n","        dataloader_test: Le DataLoader contenant les données de test.\n","\n","    Returns:\n","        float: La perte moyenne sur l'ensemble de données de test.\n","        numpy.array: Les prédictions du modèle.\n","        numpy.array: Les étiquettes réelles.\n","\n","    \"\"\"\n","    model.eval()\n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","    for batch in dataloader_test:\n","        batch = tuple(b.to(device) for b in batch)\n","        inputs = {\n","            'input_ids': batch[0],\n","            'attention_mask': batch[1],\n","            'labels': batch[2]\n","        }\n","        with torch.no_grad():\n","            outputs = model(**inputs)\n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","    loss_val_avg = loss_val_total / len(dataloader_test)\n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","    return loss_val_avg, predictions, true_vals"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def Sentiment(sent):\n","    \"\"\"\n","    Détermine le sentiment d'une phrase donnée en utilisant un modèle BERT pré-entraîné.\n","\n","    Args:\n","        sent (str): La phrase pour laquelle le sentiment doit être déterminé.\n","\n","    Returns:\n","        int: L'indice du sentiment prédit (0 pour négatif, 1 pour positif).\n","    \"\"\"\n","\n","    tokenizer = BertTokenizer.from_pretrained(output_dir)\n","    model_loaded = BertForSequenceClassification.from_pretrained(output_dir)\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,\n","                        add_special_tokens=True,\n","                        max_length=64,\n","                        pad_to_max_length=True,\n","                        return_attention_mask=True,\n","                        return_tensors='pt',\n","                   )\n","\n","    input_id = encoded_dict['input_ids']\n","\n","    attention_mask = encoded_dict['attention_mask']\n","    input_id = torch.LongTensor(input_id)\n","    attention_mask = torch.LongTensor(attention_mask)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model_loaded = model_loaded.to(device)\n","    input_id = input_id.to(device)\n","    attention_mask = attention_mask.to(device)\n","\n","    with torch.no_grad():\n","        outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n","\n","    logits = outputs[0]\n","    index = logits.argmax()\n","    return index"]},{"cell_type":"markdown","metadata":{},"source":["#### 1.3 Charghement des donnees"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# creation variable data\n","path = '../data/processed/'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":17895,"status":"ok","timestamp":1712663974262,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"wLny9FYVqjwe"},"outputs":[],"source":["# import des fichiers\n","data = pd.read_csv(path + 'data.csv')"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Preparation donnees"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1712663974262,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"foVltItws2yy"},"outputs":[],"source":["# Échantillon de tweets\n","sample_data = data[['text', 'target']].sample(n=20000, random_state=42)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1712663974263,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"Ra4Irm32s6Zs"},"outputs":[],"source":["# Récupération des étiquettes et du texte à partir de l'échantillon de données\n","labels = sample_data.target.values\n","text = sample_data.text.values"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1712663974263,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"WPUEvvwBrsTn","outputId":"46eb825b-0b56-4517-9c67-e4e8c9810229"},"outputs":[{"name":"stdout","output_type":"stream","text":["Taille de l'ensemble d'entraînement: 16800\n","Taille de l'ensemble de test: 3200\n"]}],"source":["# Séparation des données en ensembles d'entraînement et de test\n","df_train, df_testVal = train_test_split(sample_data, test_size=3200, shuffle=True)\n","\n","# Affichage des tailles des ensembles d'entraînement et de test\n","print(\"Taille de l'ensemble d'entraînement:\", len(df_train))\n","print(\"Taille de l'ensemble de test:\", len(df_testVal))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":435,"status":"ok","timestamp":1712663974694,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"ZR_9OvCjskeL","outputId":"638c0a5c-b6cb-411a-e943-22fad05738c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Taille de l'ensemble de test: 1600\n","Taille de l'ensemble de validation: 1600\n"]}],"source":["# Séparation de l'ensemble de test en ensembles de test et de validation\n","df_test, df_val = train_test_split(df_testVal, test_size=0.5, shuffle=True)\n","\n","# Affichage des tailles des ensembles de test et de validation\n","print(\"Taille de l'ensemble de test:\", len(df_test))\n","print(\"Taille de l'ensemble de validation:\", len(df_val))"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Modelisation"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.1 Tokenization"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1407,"status":"ok","timestamp":1712663976091,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"N36TN0z_s4Di","outputId":"bf723342-f7c6-4b12-debe-98253e5fb9ee"},"outputs":[],"source":["# Initialisation du tokenizer BERT avec le modèle 'bert-base-uncased'\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12686,"status":"ok","timestamp":1712663988765,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"sHyOtUiKs-UD","outputId":"8b1825ab-04fd-4248-bd49-afdb6498dabc"},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","C:\\Users\\Zacca\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["# Prétraitement des données textuelles avec le tokenizer BERT\n","input_ids = []\n","attention_mask = []\n","for i in text:\n","    encoded_data = tokenizer.encode_plus(\n","    i,\n","    add_special_tokens=True,\n","    max_length=64,\n","    pad_to_max_length = True,\n","    return_attention_mask= True,\n","    return_tensors='pt')\n","    input_ids.append(encoded_data['input_ids'])\n","    attention_mask.append(encoded_data['attention_mask'])\n","input_ids = torch.cat(input_ids,dim=0)\n","attention_mask = torch.cat(attention_mask,dim=0)\n","# Conversion des étiquettes en tenseurs\n","labels = torch.tensor(labels)"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.2 Création de l'ensemble de données des ensembles d'entraînement, de test et de validation"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1712663988765,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"AQbNZF5UtAht","outputId":"5887f8e4-ca51-4591-8e09-8d4aa5769c46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Taille de l'ensemble d'entraînement - 16000\n","Taille de l'ensemble de validation - 4000\n"]}],"source":["# Création du dataset à partir des tensors d'input_ids, de masque d'attention et d'étiquettes\n","dataset = TensorDataset(input_ids, attention_mask, labels)\n","\n","# Définition de la taille des ensembles d'entraînement et de validation\n","train_size = int(0.8 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Séparation aléatoire du dataset en ensembles d'entraînement et de validation\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","# Affichage de la taille de l'ensemble d'entraînement et de validation\n","print('Taille de l\\'ensemble d\\'entraînement -', train_size)\n","print('Taille de l\\'ensemble de validation -', val_size)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1712663988766,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"eIBCWJKgtCcP"},"outputs":[],"source":["# Chargement des données d'entraînement avec le DataLoader\n","train_dl = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=32)\n","\n","# Chargement des données de validation avec le DataLoader\n","val_dl = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size=32)"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.3 Preparation modele BERT"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":787,"status":"ok","timestamp":1712663989532,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"TmNKio0JtEr2","outputId":"9455d41a-9b32-4f70-fa7e-fb2a45172fea"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Chargement du modèle BertForSequenceClassification à partir des poids pré-entraînés\n","model = BertForSequenceClassification.from_pretrained(\n","    'bert-base-uncased',\n","    num_labels=2,  # Nombre de classes de sortie\n","    output_attentions=False,\n","    output_hidden_states=False\n",")"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1712663989533,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"nMQuhEHstPte"},"outputs":[],"source":["# Définition de l'optimiseur Adam avec un taux d'apprentissage de 2e-5 et epsilon de 1e-8\n","optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n","\n","# Définition du nombre d'époques\n","epochs = 1\n","\n","# Calcul du nombre total d'étapes\n","total_steps = len(train_dl) * epochs\n","\n","# Création du scheduler pour l'ajustement du taux d'apprentissage avec échauffement linéaire\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1712663989533,"user":{"displayName":"Zaccaria Amillou","userId":"17675153265243391628"},"user_tz":-120},"id":"GV1fyqFqtRt_","outputId":"67f6c6a9-f1a1-4c9c-a16d-7acbd862c1df"},"outputs":[{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["#### 3.4 Entrainement modele BERT"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Epoch 1\n","Training loss: 0.4498463813662529\n","Validation loss: 0.4030902409553528\n","Accuracy: 0.82675\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\Zacca\\anaconda3\\Lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n","  warnings.warn(\"Setuptools is replacing distutils.\")\n"]}],"source":["# Start a new MLflow run\n","with mlflow.start_run(run_name='Bert Model'):\n","\n","    # Libération de la mémoire GPU\n","    torch.cuda.empty_cache()\n","\n","    # Boucle d'entraînement sur les époques\n","    for epoch in range(1, epochs+1):\n","\n","        # Mettre le modèle en mode d'entraînement\n","        model.train()\n","\n","        # Initialisation de la perte totale d'entraînement\n","        loss_train_total = 0\n","\n","        for batch in train_dl:\n","\n","            # Remise à zéro du gradient\n","            model.zero_grad()\n","\n","            # Transfert du batch sur le périphérique GPU\n","            batch = tuple(b.to(device) for b in batch)\n","\n","            # Extraction des entrées du batch\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'labels':         batch[2],\n","                     }\n","\n","            # Propagation avant à travers le modèle\n","            outputs = model(**inputs)\n","\n","            # Calcul de la perte\n","            loss = outputs[0]\n","            loss_train_total += loss.item()\n","            loss.backward()\n","\n","            # Clip des gradients pour éviter l'explosion du gradient\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","            # Mise à jour des poids du modèle\n","            optimizer.step()\n","            scheduler.step()\n","\n","        # Affichage des informations à la fin de chaque époque\n","        print(f'\\nEpoch {epoch}')\n","\n","        # Calcul de la perte moyenne d'entraînement\n","        loss_train_avg = loss_train_total/len(train_dl)\n","        print(f'Training loss: {loss_train_avg}')\n","\n","        # Log the training loss\n","        mlflow.log_metric(\"training_loss\", loss_train_avg)\n","\n","        # Évaluation sur l'ensemble de validation\n","        val_loss, predictions, true_vals = evaluate(val_dl)\n","\n","        # Calcul de la précision sur l'ensemble de validation\n","        val_acc = accuracy(predictions, true_vals)\n","\n","        # Log the validation loss and accuracy\n","        mlflow.log_metric(\"validation_loss\", val_loss)\n","        mlflow.log_metric(\"accuracy\", val_acc)\n","\n","        # Affichage des résultats de validation\n","        print(f'Validation loss: {val_loss}')\n","        print(f'Accuracy: {val_acc}')\n","\n","    # Log the model\n","    mlflow.pytorch.log_model(model, \"model\")"]},{"cell_type":"markdown","metadata":{},"source":["### 4. Sauvegarde du modèle"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["('../model/BERT\\\\tokenizer_config.json',\n"," '../model/BERT\\\\special_tokens_map.json',\n"," '../model/BERT\\\\vocab.txt',\n"," '../model/BERT\\\\added_tokens.json')"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Répertoire de sortie pour enregistrer le modèle et le tokenizer\n","output_dir = '../model/BERT'\n","\n","# Sauvegarde du modèle\n","model_to_save = model.module if hasattr(model, 'module') else model\n","model_to_save.save_pretrained(output_dir)\n","\n","# Sauvegarde du tokenizer\n","tokenizer.save_pretrained(output_dir)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Chargement du tokenizer BERT...\n"]}],"source":["# Chargement du tokenizer BERT\n","print('Chargement du tokenizer BERT...')\n","output_dir = '../model/BERT'\n","tokenizer = BertTokenizer.from_pretrained(output_dir)\n","model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"]},{"cell_type":"markdown","metadata":{},"source":["#### 5. Test du modèle sur un exemple"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","C:\\Users\\Zacca\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["# test modele bert\n","test = Sentiment('it was a great movie')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Positive\n"]}],"source":["# affichage resultat\n","if test == 1:\n","    print(\"Positive\")\n","else:\n","    print(\"Negative\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOUAkrPOLABi6bF9LCvb1Zr","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"03a20099d816459da42d545beeebe2fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19989327fd8643d89aba181c921e609e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1da8548a659348cdaf07bfd52ccc05db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2473e0f8bf8144419497fb5700a059a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_877ad9a377784170a00ffc8cbf886885","placeholder":"​","style":"IPY_MODEL_401bda723eb647d8aa43881d8709bac8","value":" 0/1 [00:00&lt;?, ?it/s]"}},"2b883e0e80984845a900cfbaf714c2c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d9af6bf9030431381b5614668cc03c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"401bda723eb647d8aa43881d8709bac8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"493a29b222734460b0d8e4ad2f678a72":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5119be6f655446fcbbef78a8cf55b083":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1da8548a659348cdaf07bfd52ccc05db","placeholder":"​","style":"IPY_MODEL_19989327fd8643d89aba181c921e609e","value":"Epoch 1:   3%"}},"536c4fe43e49478f9546a273d41dee02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_03a20099d816459da42d545beeebe2fe","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57f36a4ce914486db0c4b57541a24348","value":13}},"57f36a4ce914486db0c4b57541a24348":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"773e655d83e94aceb807f0e962b6757a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7eb81f9c0ce94a65952ccc250b1783c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"877ad9a377784170a00ffc8cbf886885":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89c44efda0584761b230caf0e8f290b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d37767e0456948048ed2136d66a67241","placeholder":"​","style":"IPY_MODEL_dbb25f6ddb694bb0bf09ff2673eda40a","value":" 13/500 [04:48&lt;3:09:42, 23.37s/it, training_loss=0.229]"}},"aa63056bd39d4f4ab628661e1baaaabf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf94b1c05157408895756840e9f4c1dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7eb81f9c0ce94a65952ccc250b1783c9","placeholder":"​","style":"IPY_MODEL_3d9af6bf9030431381b5614668cc03c8","value":"  0%"}},"d00eb53748a8446da3d20f5e5d10d845":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5119be6f655446fcbbef78a8cf55b083","IPY_MODEL_536c4fe43e49478f9546a273d41dee02","IPY_MODEL_89c44efda0584761b230caf0e8f290b5"],"layout":"IPY_MODEL_2b883e0e80984845a900cfbaf714c2c5"}},"d37767e0456948048ed2136d66a67241":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbb25f6ddb694bb0bf09ff2673eda40a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8bf1f4f653f4b589ae934bcc386de99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bf94b1c05157408895756840e9f4c1dc","IPY_MODEL_fdd62d1c07ce429faa5f4fb0d7257751","IPY_MODEL_2473e0f8bf8144419497fb5700a059a6"],"layout":"IPY_MODEL_493a29b222734460b0d8e4ad2f678a72"}},"fdd62d1c07ce429faa5f4fb0d7257751":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa63056bd39d4f4ab628661e1baaaabf","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_773e655d83e94aceb807f0e962b6757a","value":0}}}}},"nbformat":4,"nbformat_minor":0}
